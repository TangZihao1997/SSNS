{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "554018d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torchvision.models.resnet import ResNet18_Weights\n",
    "from torchvision import transforms\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf380fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_vector(img_tensor):\n",
    "    # Assume img_tensor is already a preprocessed tensor\n",
    "    t_img = Variable(img_tensor)\n",
    "\n",
    "    #Create a zero vector that will hold the feature vector\n",
    "    # The 'avgpool' layer has an output size of 512\n",
    "    my_embedding = torch.zeros(1, 512, 1, 1)\n",
    "\n",
    "    #Define a function to copy the output of a layer\n",
    "    def copy_data(m, i, o):\n",
    "        my_embedding.copy_(o.data)\n",
    "\n",
    "    # Attach the function to our selected layer\n",
    "    h = layer.register_forward_hook(copy_data)\n",
    "\n",
    "    # Run the model on our transformed image\n",
    "    model(t_img)\n",
    "\n",
    "    # Detach our copy function from the layer\n",
    "    h.remove()\n",
    "\n",
    "    # Return the feature vector\n",
    "    return my_embedding.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa51b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_features(input_base_folder, output_base_folder):\n",
    "    folder_counter = 1\n",
    "\n",
    "    for subdir, dirs, files in os.walk(input_base_folder):\n",
    "        if not files:  # Skip directories without files\n",
    "            continue\n",
    "\n",
    "        all_feature_vectors = []  # Collect feature vectors for this folder\n",
    "\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.jpeg'):\n",
    "                img_path = os.path.join(subdir, file)\n",
    "                img = Image.open(img_path)\n",
    "                img = convert_to_3_channels(img)  # Convert to 3 channels if needed\n",
    "                img_tensor = preprocess(img)  # Apply preprocessing\n",
    "                img_tensor = img_tensor.unsqueeze(0)  # Add an extra batch dimension\n",
    "\n",
    "                feature_vector = extract_feature_vector(img_tensor)  # Extract feature vector\n",
    "                all_feature_vectors.append(feature_vector)\n",
    "\n",
    "        # 将特征向量转换为 NumPy 数组并使用 PCA 降维\n",
    "        all_feature_vectors_np = np.array(all_feature_vectors)\n",
    "        pca = PCA(n_components=30)\n",
    "        reduced_vectors = pca.fit_transform(all_feature_vectors_np)\n",
    "\n",
    "        # 为当前文件夹创建输出目录\n",
    "        current_output_folder = os.path.join(output_base_folder, f\"train_feature{folder_counter}\")\n",
    "        if not os.path.exists(current_output_folder):\n",
    "            os.makedirs(current_output_folder)\n",
    "\n",
    "        # 保存降维后的特征向量，文件名从1开始计数\n",
    "        for i, reduced_vector in enumerate(reduced_vectors, start=1):\n",
    "            output_path = os.path.join(current_output_folder, f\"{i}.npy\")\n",
    "            np.save(output_path, reduced_vector)\n",
    "\n",
    "        folder_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca0bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_and_save_features(input_base_folder, output_base_folder):\n",
    "#     folder_counter = 1\n",
    "\n",
    "#     for subdir, dirs, files in os.walk(input_base_folder):\n",
    "#         if not files:  # 跳过没有文件的目录\n",
    "#             continue\n",
    "\n",
    "#         output_folder = os.path.join(output_base_folder, f\"train_feature{folder_counter}\")\n",
    "#         if not os.path.exists(output_folder):\n",
    "#             os.makedirs(output_folder)\n",
    "\n",
    "#         counter = 1\n",
    "#         for file in files:\n",
    "#             if file.lower().endswith('.jpeg'):\n",
    "#                 img_path = os.path.join(subdir, file)\n",
    "#                 img = Image.open(img_path)  # PIL image\n",
    "#                 img_tensor = preprocess(img)  # Apply preprocessing\n",
    "#                 img_tensor = img_tensor.unsqueeze(0)  # Add an extra batch dimension\n",
    "\n",
    "#                 feature_vector = extract_feature_vector(img_tensor)  # Directly use the tensor\n",
    "#                 feature_vector_np = feature_vector.squeeze()\n",
    "\n",
    "#                 # Save the feature vector to a file\n",
    "#                 output_path = os.path.join(output_folder, str(counter) + '.npy')\n",
    "#                 np.save(output_path, feature_vector_np)\n",
    "\n",
    "#                 counter += 1\n",
    "\n",
    "#         folder_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e944272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_3_channels(img):\n",
    "    \"\"\"Convert an image to 3 channels if it's not already.\"\"\"\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd413e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained ResNet18 model using the new weights parameter\n",
    "model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Select the layer from which to extract features\n",
    "layer = model.avgpool\n",
    "# Normalize transform\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# Define the image preprocessing function\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Lambda(convert_to_3_channels), \n",
    "    transforms.Resize(256, antialias=True),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3709611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用函数\n",
    "input_base_folder = './train'\n",
    "output_base_folder = './train_feature'\n",
    "process_and_save_features(input_base_folder, output_base_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f848a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d5c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
